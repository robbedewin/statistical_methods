{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160f5c00-77ee-4741-bb50-d9d92d777729",
   "metadata": {},
   "source": [
    "# Exercise 5.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa88ff-5324-490e-bcb5-10e4b11f9935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"ISLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b87472-c01d-4be0-bffe-cdb2426b67e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from ISLP import load_data\n",
    "Default = load_data('Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d5b51-5522-4a90-8e47-33aa3a795744",
   "metadata": {},
   "source": [
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach.\n",
    "\n",
    "a. & b. Fit a logistic regression model that uses income and balance to predict default. Using the validation set approach, estimate the test error of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb909616-bd59-4859-a2d3-8deff2cde2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080110\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 6666\n",
      "Model:                          Logit   Df Residuals:                     6663\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 20 May 2025   Pseudo R-squ.:                  0.4714\n",
      "Time:                        00:43:14   Log-Likelihood:                -534.01\n",
      "converged:                       True   LL-Null:                       -1010.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.416e-207\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -11.7722      0.534    -22.060      0.000     -12.818     -10.726\n",
      "income      2.299e-05   6.08e-06      3.781      0.000    1.11e-05    3.49e-05\n",
      "balance        0.0058      0.000     20.645      0.000       0.005       0.006\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "                        Generalized Linear Model Regression Results                        \n",
      "===========================================================================================\n",
      "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                 6666\n",
      "Model:                                         GLM   Df Residuals:                     6663\n",
      "Model Family:                             Binomial   Df Model:                            2\n",
      "Link Function:                               Logit   Scale:                          1.0000\n",
      "Method:                                       IRLS   Log-Likelihood:                -534.01\n",
      "Date:                             Tue, 20 May 2025   Deviance:                       1068.0\n",
      "Time:                                     00:43:14   Pearson chi2:                 3.92e+03\n",
      "No. Iterations:                                  9   Pseudo R-squ. (CS):             0.1332\n",
      "Covariance Type:                         nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     11.7722      0.534     22.060      0.000      10.726      12.818\n",
      "income     -2.299e-05   6.08e-06     -3.781      0.000   -3.49e-05   -1.11e-05\n",
      "balance       -0.0058      0.000    -20.645      0.000      -0.006      -0.005\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#exercise 5a,b I and II\n",
    "np.random.seed(2)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "train, test = train_test_split(Default, test_size=1/3, random_state=1)\n",
    "\n",
    "# Logistic regression: one way\n",
    "X_train = train[[\"income\", \"balance\"]]\n",
    "y_train = (train[\"default\"] == \"Yes\").astype(int)\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "model1 = sm.Logit(y_train, X_train).fit()\n",
    "print(model1.summary())\n",
    "#another way\n",
    "model2 = smf.glm(\"default ~ income + balance\", data=train, family=sm.families.Binomial(link=sm.families.links.Logit()))\n",
    "result2=model2.fit()\n",
    "print(result2.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92bff5d-7c55-486a-a0d5-21e9ce781670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3216   18]\n",
      " [  63   37]]\n",
      "Misclassification Rate: 2.43%\n",
      "[[3234    0]\n",
      " [ 100    0]]\n",
      "Misclassification Rate: 3.00%\n"
     ]
    }
   ],
   "source": [
    "#5b III\n",
    "# Predictions on test set\n",
    "X_test = test[[\"income\", \"balance\"]]\n",
    "y_test = (test[\"default\"] == \"Yes\").astype(int)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "pred_probs = model1.predict(X_test) #prediction of default status for each individual in the validation set\n",
    "\n",
    "predictions = pred_probs > 0.5 # classification\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "# 5b IV, Misclassification rate\n",
    "miss_class = np.mean(predictions != y_test)\n",
    "print(f\"Misclassification Rate: {miss_class * 100:.2f}%\")\n",
    "\n",
    "#note the imbalance in categories! If you just say always default=No you get a rate of :\n",
    "\n",
    "predictions=np.zeros(len(predictions))\n",
    "miss_classAlwaysNo = np.mean(predictions != y_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(f\"Misclassification Rate: {miss_classAlwaysNo * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd3f1a-6f7f-47cc-8826-3488cab4608d",
   "metadata": {},
   "source": [
    "c. Repeat the fitting and splitting process three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a26e65f-07cf-4889-83fa-1c87d43fd03b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7594481103779245, 2.4295140971805638, 2.489502099580084]\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(3):\n",
    "    np.random.seed(i+10)\n",
    "    # Split data into training and test sets\n",
    "    train, test = train_test_split(Default, test_size=1/3, random_state=i)\n",
    "    \n",
    "    # Fit logistic regression models\n",
    "    X_train = train[[\"income\", \"balance\"]]\n",
    "    y_train = (train[\"default\"] == \"Yes\").astype(int)\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    X_test = test[[\"income\", \"balance\"]]\n",
    "    y_test = (test[\"default\"] == \"Yes\").astype(int)\n",
    "    X_test = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "    model1 = sm.Logit(y_train, X_train).fit(disp=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_probs = model1.predict(X_test)\n",
    "    y_test = (test[\"default\"] == \"Yes\").astype(int)\n",
    "    predictions = pred_probs > 0.5\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    # Misclassification rates\n",
    "    miss_class = np.mean(predictions != y_test)\n",
    "    results.append(miss_class * 100)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c1bae-9047-4a5e-b862-43736a05bd9f",
   "metadata": {},
   "source": [
    "So we see that there is variability in the estimated missclassification rate. This variable is a random variable with a degree of uncertainty about the actual (infinite population) value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355330df-035c-4483-bf7b-51a8085aa241",
   "metadata": {},
   "source": [
    "d. Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d514a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 6666\n",
      "Model:                          Logit   Df Residuals:                     6662\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 20 May 2025   Pseudo R-squ.:                  0.4760\n",
      "Time:                        00:43:37   Log-Likelihood:                -546.67\n",
      "converged:                       True   LL-Null:                       -1043.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.439e-215\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.5802      0.574    -18.424      0.000     -11.706      -9.455\n",
      "income     -3.281e-06   9.62e-06     -0.341      0.733   -2.21e-05    1.56e-05\n",
      "balance        0.0058      0.000     21.003      0.000       0.005       0.006\n",
      "student       -0.8978      0.278     -3.227      0.001      -1.443      -0.352\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "2.489502099580084\n"
     ]
    }
   ],
   "source": [
    "#5d\n",
    "X_train = train[[\"income\", \"balance\"]].copy()\n",
    "X_train[\"student\"]=(train[\"student\"] == \"Yes\").astype(int)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = test[[\"income\", \"balance\"]].copy()\n",
    "X_test[\"student\"]=(test[\"student\"] == \"Yes\").astype(int)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "model3 = sm.Logit(y_train, X_train).fit(disp=False)\n",
    "print(model3.summary())\n",
    "pred_probs = model3.predict(X_test) #prediction of default status for each individual in the validation set\n",
    "predictions = pred_probs > 0.5\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "miss_class = np.mean(predictions != y_test)\n",
    "print(miss_class*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f669b40-1ae4-4b2f-a4aa-205ace078b96",
   "metadata": {},
   "source": [
    "The student variable coefficient is significant (and interacts with income which is no longer significant). This indicates that adding student might be useful. The misclassification error on our particular training set is slightly higher though: adding the variable does not appear to offer benefit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
