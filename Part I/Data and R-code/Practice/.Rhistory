# Install the libraries if they are not already installed.
install.packages(c("glmnet", "mgcv", "randomForest", "gbm", "corrplot", "pROC"))
knitr::opts_chunk$set(error = TRUE)
x <- c(1, 3, 2, 5)
x
###
x <- c(1, 3, 2, 5)
x
###
x = c(1, 6, 2)
x
y = c(1, 4, 3)
library(lme4)
library(lmerTest)
library(readxl)
#Fit model from exam
long_teaching <- read_csv("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Exam/long_teaching.txt")
#Fit model from exam
library(readr)
long_teaching <- read_csv("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Exam/long_teaching.txt")
View(long_teaching)
attach(long_teaching)
model_fit <- lmer(y ~ time * prog + (1 |id), data = long_teaching, REML = FALSE)
model_fit_random_slope <- lmer(y ~ time * prog + (1 + time |id), data = long_teaching, REML = FALSE)
# Get the detailed summary of our fitted model
model_summary <- summary(model_fit)
print(model_summary)
summary(model_fit_random_slope)
var_between <- VarCorr(model_fit)$id[1,1]
var_within <- sigma(model_fit)^2
print(paste("Variance BETWEEN individuals (sigma_0^2):", round(var_between, 2)))
print(paste("Variance WITHIN individuals (sigma_epsilon^2):", round(var_within, 2)))
if (var_between > var_within) {
print("Conclusion 1: The variability between individuals is larger than the variability within individuals.")
} else {
print("Conclusion 1: The variability between individuals is smaller than the variability within individuals.")
}
# Extract the interaction term's results
interaction_term <- coef(model_summary)["time:prog", ]
estimate_g11 <- interaction_term["Estimate"]
p_value_g11 <- interaction_term["Pr(>|t|)"]
print(paste("Estimate for gamma_11 (time:prog):", round(estimate_g11, 2)))
print(paste("P-value for gamma_11 (time:prog):", round(p_value_g11, 4)))
if (estimate_g11 > 0 & p_value_g11 < 0.05) {
print("Conclusion 2: As an average the new program is significantly better than the standard program.")
} else if (estimate_g11 > 0 & p_value_g11 >= 0.05) {
print("Conclusion 2: As an average based on the point estimates the new program seems to be better than the standard program but the result is not significant.")
} else {
# Handle other cases if necessary
}
main_effect_prog <- coef(model_summary)["prog", ]
estimate_g01 <- main_effect_prog["Estimate"]
p_value_g01 <- main_effect_prog["Pr(>|t|)"]
print(paste("Estimate for gamma_01 (prog):", round(estimate_g01, 2)))
print(paste("P-value for gamma_01 (prog):", round(p_value_g01, 4)))
if (p_value_g01 >= 0.05) {
print(paste("Conclusion 3: The point estimate for the main effect of program is",
ifelse(estimate_g01 > 0, "positive", "negative"), "and not significant."))
} else {
# Handle other cases
}
coeffs <- fixef(model_fit)
gamma_00_hat <- coeffs["(Intercept)"]
gamma_01_hat <- coeffs["prog"]
gamma_10_hat <- coeffs["time"]
gamma_11_hat <- coeffs["time:prog"]
predicted_score <- gamma_00_hat + (gamma_01_hat * 0) + (gamma_10_hat * 1) + (gamma_11_hat * 0 * 1)
print(paste("Conclusion 4: The predicted average score is:", round(predicted_score, 2)))
print(paste("P-value for gamma_01 (prog) is:", round(p_value_g01, 4)))
if (p_value_g01 < 0.05) {
print("Conclusion 5: The p-value associated with gamma_01 is smaller than 5%")
} else if (p_value_g01 >= 0.05 & p_value_g01 <= 0.80) {
print("Conclusion 5: The p-value associated with gamma_01 is between 5% and 80%")
} else if (p_value_g01 > 0.90) {
print("Conclusion 5: The p-value associated with gamma_01 is larger than 90%")
} else {
print("Conclusion 5: The p-value is in another range.")
}
print(model_summary)
summary(model_fit_random_slope)
print(model_summary)
summary(model_fit_random_slope)
var_between <- VarCorr(model_fit)$id[1,1]
var_within <- sigma(model_fit)^2
print(paste("Variance BETWEEN individuals (sigma_0^2):", round(var_between, 2)))
print(paste("Variance WITHIN individuals (sigma_epsilon^2):", round(var_within, 2)))
if (var_between > var_within) {
print("Conclusion 1: The variability between individuals is larger than the variability within individuals.")
} else {
print("Conclusion 1: The variability between individuals is smaller than the variability within individuals.")
}
print(model_summary)
detach(lmerTest)
lme4::summary(model_fit)
lme4::summary(model_fit)
# Get the detailed summary of our fitted model
detach("package:lmerTest", unload=TRUE)
model_summary <- summary(model_fit)
print(model_summary)
# Get the detailed summary of our fitted model
detach("package:lmerTest", unload=TRUE)
model_fit <- lmer(y ~ time * prog + (1 |id), data = long_teaching, REML = FALSE)
model_summary <- summary(model_fit)
print(model_summary)
library(lmerTest)
model_fit <- lmer(y ~ time * prog + (1 |id), data = long_teaching, REML = FALSE)
model_summary <- summary(model_fit)
print(model_summary)
summary(model_fit_random_slope)
setwd("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Practice")
library(lme4)
library(readr)
Lecture3_4_rat_pup <- read_table("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Lecture3&4_rat_pup.txt",
col_types = cols(pupid = col_integer(),
litterid = col_integer(), litsize = col_integer()))
View(Lecture3_4_rat_pup)
rat_pup <- read_table("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Lecture3&4_rat_pup.txt",
col_types = cols(pupid = col_integer(),
litterid = col_integer(), litsize = col_integer()))
rat_pup$treatment <- as.factor(rat_pup$treatment)
levels(rat_pup$treatment)
rat_pup$sex <- as.factor(rat_pup$sex)
model_pup <- lmer(weight ~ sex * treatment * litsize + (1 | pupid), data = rat_pup, REML = FALSE)
model_pup <- lmer(weight ~ sex * treatment * litsize + (1 | litterid), data = rat_pup, REML = FALSE)
summary(model_pup)
model_pup <- lmer(weight ~ sex + treatment + litsize + sex * treatment (1 | litterid), data = rat_pup, REML = FALSE)
model_pup <- lmer(weight ~ sex + treatment + litsize + treatment * sex (1 | litterid), data = rat_pup, REML = FALSE)
model_pup <- lmer(weight ~ sex + treatment + litsize + treatment:sex (1 | litterid), data = rat_pup, REML = FALSE)
levels(rat_pup$treatment)
model_pup <- lmer(weight ~ sex + treatment + litsize + treatment:sex + (1 | litterid), data = rat_pup, REML = FALSE)
summary(model_pup)
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = ratpup,
method = "REML")
library(nlme)
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = ratpup,
method = "REML")
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = rat_pup,
method = "REML")
summary(model_hom)
model_hom <- ?lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = rat_pup,
method = "REML")
?lme
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = rat_pup,
method = "ML")
summary(model_hom)
summary(model_pup)
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = rat_pup,
method = "ML")
summary(model_hom)
model_hom <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
data = rat_pup,
method = "REML")
summary(model_hom)
model_het <- lme(weight ~ treat + sex1 + litsize + treat:sex1,
random = ~1 | litterid,
weights = varIdent(form = ~ 1 | treat), # <-- This is the key addition
data = ratpup,
method = "REML")
model_het <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
weights = varIdent(form = ~ 1 | treat), # <-- This is the key addition
data = rat_pup,
method = "REML")
model_het <- lme(weight ~ treatment + sex + litsize + treatment:sex,
random = ~1 | litterid,
weights = varIdent(form = ~ 1 | treatment), # <-- This is the key addition
data = rat_pup,
method = "REML")
anova(model_hom, model_het)
source("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Practice/missing_data.R", echo = TRUE)
Lecture5_titanic <- read_csv("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Lecture5_titanic.txt",
col_types = cols(age = col_double()))
View(Lecture5_titanic)
# Load the library
library(mice)
# Tell mice to create 100 imputed datasets
imp <- mice(titanic.missing, m = 100)
titanic_missing <- read_csv("~/KULeuven/Bioinformatics_2024-2025/Statistical_Methods/Part I/Data and R-code/Lecture5_titanic.txt",
col_types = cols(age = col_double()))
# Tell mice to create 100 imputed datasets
imp <- mice(titanic.missing, m = 100)
# Tell mice to create 100 imputed datasets
imp <- mice(titanic_missing, m = 100)
View(Lecture5_titanic)
# 'with' takes the imputed object and the model you want to run
fit <- with(data = imp,
exp = glm(survived ~ pclass + sex + age, family = binomial))
# 'pool' combines the results
final_estimates <- pool(fit)
summary(final_estimates)
summary(fit)
head(titanic_missing)
titanic_missing<-subset(titanic_missing,select=c('survived','pclass','sex','age'))
titanic.missing$sex<-as.numeric(titanic_missing$sex)-1
titanic.missing <- titanic_missing
titanic.missing$sex<-as.numeric(titanic.missing$sex)-1
head(titanic.missing)
titanic.missing$sex[sample(nrow(titanic.missing), 10)] <- NA
set.seed(4321)
titanic.missing$sex[sample(nrow(titanic.missing), 10)] <- NA
titanic.missing.aggr=aggr(titanic.missing,numbers = TRUE, prop = FALSE, ylab=c("Histogram of missing data","Pattern"))
install.packages("mice")
install.packages("lattice")
install.packages("VIM")
install.packages("aod") # neccesary for the Wald test
install.packages("xtable")
install.packages("BaM")  # neccesary for generating multivariate normals in the simulations
install.packages("MASS")
install.packages("nnet")
library(mice)
library(lattice)
library(VIM)
library(aod)
library(xtable)
library(BaM)
titanic.missing.aggr=aggr(titanic.missing,numbers = TRUE, prop = FALSE, ylab=c("Histogram of missing data","Pattern"))
library(mice)
library(lattice)
library(VIM)
library(aod)
library(xtable)
library(BaM)
setwd("C:\\Users\\u0065129\\OneDrive\\Equizo\\Courses\\KULeuven\\Bioinformatics\\Missing-Data\\R-code")
titanic.missing.aggr=aggr(titanic.missing,numbers = TRUE, prop = FALSE, ylab=c("Histogram of missing data","Pattern"))
titanic.missing <- titanic_missing
titanic.missing$sex<-as.factor(titanic.missing$sex)
titanic.missing.aggr=aggr(titanic.missing,numbers = TRUE, prop = FALSE, ylab=c("Histogram of missing data","Pattern"))
titanic.missing.aggr
set.seed(4321)
titanic.missing$sex[sample(nrow(titanic.missing), 10)] <- NA
titanic.missing.aggr=aggr(titanic.missing,numbers = TRUE, prop = FALSE, ylab=c("Histogram of missing data","Pattern"))
titanic.missing.aggr
aggr(titanic.missing, combined=TRUE, numbers = TRUE, prop = TRUE,cex.numbers=0.87, varheight = FALSE)
barMiss(titanic.missing)
histMiss(titanic.missing)
titanic.missing$survived <- as.factor(titanic.missing$survived)
barMiss(titanic.missing[,c("sex","age")])
barMiss(titanic.missing)
histMiss(titanic.missing)
matrixplot(titanic.missing)
titanic.logistic.omit<-glm(survived ~ pclass + sex + age, family=binomial, data = titanic.missing)
summary(titanic.logistic.omit)
confint(titanic.logistic.omit)
wald.test(b=coef(titanic.logistic.omit), Sigma=vcov(titanic.logistic.omit), Terms=2:3)
titanic.logistic.omit.table<-xtable(titanic.logistic.omit,digits=2)
print(titanic.logistic.omit.table)
odds.point.omit<-exp(titanic.logistic.omit$coefficients)
odds.CI.omit<-exp(confint(titanic.logistic.omit))
exp(cbind(OR =titanic.logistic.omit$coefficients, confint(titanic.logistic.omit)))
# Tell mice to create 100 imputed datasets
imp <- mice(titanic.missing, m = 100)
# 'with' takes the imputed object and the model you want to run
fit <- with(data = imp,
exp = glm(survived ~ pclass + sex + age, family = binomial))
# 'pool' combines the results
final_estimates <- pool(fit)
summary(final_estimates)
?glm
